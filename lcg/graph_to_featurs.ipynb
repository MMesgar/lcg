{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                  author: Mohsen Mesgar\n",
    "###############################################################################\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "import sys, copy, time, math, pickle\n",
    "import cPickle as cpickle\n",
    "import itertools\n",
    "import scipy.io\n",
    "import pynauty\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys, getopt\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from subgraph_struc import read, write,get_canonical_map,draw, graph_to_adj_matrix as graph2am, recover_graph, draw\n",
    "from graph_set import read_graph_set as read_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def drawProgressBar(shell_out, \n",
    "                    begin, k, out_of, end, barLen =25):\n",
    "    percent = k/float(out_of)\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    progress = \"\"\n",
    "    for i in range(barLen):\n",
    "        if i < int(barLen * percent):\n",
    "            progress += \"=\"\n",
    "        elif i==int(barLen * percent):\n",
    "            progress +='>'\n",
    "        else:\n",
    "            progress += \"_\"\n",
    "    text = \"%s%d/%d[%s](%.2f%%)%s\"%(begin,k,out_of,progress,percent * 100, end)\n",
    "    if shell_out== True:\n",
    "        sys.stdout.write(text)\n",
    "        sys.stdout.flush()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                   get pattern canonical map without node order\n",
    "###############################################################################\n",
    "def get_canonical_map(g):\n",
    "    if len(g.nodes())>0:\n",
    "        a = nx.adjacency_matrix(g)\n",
    "        am = a.todense()\n",
    "        window = np.array(am)\n",
    "        adj_mat = {idx: [i for i in list(np.where(edge)[0]) if i!=idx] for idx, edge in enumerate(window)}\n",
    "#       This line doesn't take into account the order of nodes, it produces the identical\n",
    "#       canonoical map for these graphs\n",
    "#       0-->1 2, 0 1-->2, 0-->2 1\n",
    "#        tmp = pynauty.Graph(number_of_vertices=len(g.nodes()), directed=True, adjacency_dict = adj_mat) \n",
    "\n",
    "        tmp = pynauty.Graph(number_of_vertices=len(g.nodes()), directed=True, adjacency_dict = adj_mat, \n",
    "                    vertex_coloring = [set([t]) for t in range(len(g.nodes(0)))],) \n",
    "\n",
    "        cert = pynauty.certificate(tmp)\n",
    "    else:\n",
    "        cert = ''\n",
    "    return cert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                               read graph maps\n",
    "###############################################################################\n",
    "def get_maps(can_map_file, count_file):\n",
    "    # canonical_map -> {canonical string id: {\"graph\", \"idx\", \"n\"}}\n",
    "    canonical_map = read(can_map_file)\n",
    "    \n",
    "   \n",
    "   # weight map -> {parent id: {child1: weight1, ...}}\n",
    "    weight_map = read(count_file)\n",
    "    \n",
    "    \n",
    "    weight_map = {parent: {child: weight/float(sum(children.values())) for child, weight in children.items()} \n",
    "                    for parent, children in weight_map.items()}\n",
    "    child_map = {}\n",
    "    for parent, children in weight_map.items():\n",
    "        for k,v in children.items():\n",
    "            if k not in child_map:\n",
    "                child_map[k] = {}\n",
    "            child_map[k][parent] = v\n",
    "    weight_map = child_map\n",
    "    return canonical_map, weight_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                  compute the base probability\n",
    "###############################################################################\n",
    "def pb(graph_id, weight_map):\n",
    "    parents =  weight_map[graph_id] \n",
    "    total = 0    \n",
    "    for k,w in parents.items():\n",
    "        total = w*pb(k, weight_map)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "###############################################################################\n",
    "##                compute the count of each pattrn in each graph\n",
    "###############################################################################\n",
    "def pattern_counter_in_graph(inputs):\n",
    "    gidx = inputs[0]\n",
    "    graph = inputs[1]\n",
    "    min_pattern_size = inputs[2] \n",
    "    max_pattern_size = inputs[3]\n",
    "    samplesize = inputs[4] \n",
    "    canonical_map = inputs[5]\n",
    "    \n",
    "    # in case we don't observe any graphlet in the graph, we fallback to the graphlet id that has zero edges in it\n",
    "    #fallback_map = {1: 1, 2: 2, 3: 4, 4: 8, 5: 19, 6: 53,       7: 209, 8: 1253, 9: 13599}\n",
    "    fallback_map = {1: 1, 2: 3, 3: 11, 4: 75, 5: 1099, 6: 13901}\n",
    "    # initialize the seed \t\n",
    "    seed = 1        \n",
    "    np.random.seed(seed)   \n",
    "    \n",
    "    am = graph2am(graph)\n",
    "    graph_size = len(am)\n",
    "    \n",
    "    # count_map = {node id: absolute count, ...}\n",
    "    count_map = {}\n",
    "    \n",
    "    \n",
    "    for pattern_size in range(min_pattern_size, max_pattern_size+1):\n",
    "        #print \"pattern_size=\", pattern_size\n",
    "        \n",
    "        # we don't need to loop if size of the adj. matrix is smaller than n        \n",
    "        if graph_size >= pattern_size:\n",
    "            count = 0\n",
    "            sample_set =[]\n",
    "            ub = scipy.misc.comb(graph_size, pattern_size)\n",
    "            while (len(sample_set) <= samplesize and len(sample_set) < ub):\n",
    "                #print \"sample_set=\", sample_set\n",
    "                r = random.sample(range(graph_size), pattern_size)\n",
    "                r_sort = np.sort(r).tolist()\n",
    "                \n",
    "                #print \"r\",r\n",
    "                #print \"r_sort\",r_sort\n",
    "                \n",
    "                if sample_set.count(r_sort)==0:\n",
    "                    sample_set.append(r_sort)\n",
    "                    count = count + 1\n",
    "                #print \"count\",count\n",
    "                \n",
    "        #    for s in range(samplesize):\n",
    "            #print \"final_sample_set=\", sample_set\n",
    "            #print \"final_count\", count\n",
    "            for s in sample_set:\n",
    "                #print \"sample=\",s\n",
    "                window = am[np.ix_(s,s)]\n",
    " \n",
    "                # fekr konam window bayyad ye jori graph bashe\n",
    "                pattern = nx.DiGraph(window)\n",
    "                g_type = canonical_map[get_canonical_map(pattern)][\"idx\"]               \n",
    "                #print \"g_type\", g_type\n",
    "                \n",
    "                # increment the count of seen graphlet\n",
    "                count_map[g_type] = count_map.get(g_type,0)+ 1.0\n",
    "                #print  \"count_map[g_type]\", count_map[g_type]\n",
    "\n",
    "        else:\n",
    "            # fallback to 0th node at that level\n",
    "            count_map[fallback_map[pattern_size]] = samplesize\n",
    "            #print \"In_fall_back\",\"count_map[fallback_map[pattern_size]]\",count_map[fallback_map[pattern_size]]\n",
    "  \n",
    "    return (gidx, count_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##           compute the count of subgraphs for each graph in graph set\n",
    "## graph_set: a dictionary of graphs and their id. {idx1:graph1, idx2:graph2,...}\n",
    "###############################################################################\n",
    "from joblib import Parallel, delayed\n",
    "def count_subgraphs(graph_set_file, min_pattern_size, max_pattern_size, sample_size,\n",
    "                    can_map, output_file, threshold):\n",
    " \n",
    "    ## read graph_set\n",
    "    print \"loading the graph_set_file ...: %s\"%graph_set_file\n",
    "    graph_set = read_graph_set(graph_set_file, threshold)\n",
    "    print \"# graphs in graph_set: %d\"%len(graph_set)\n",
    "\n",
    "    #    for gidx, value in graph_set.items():\n",
    "#        graph = value['graph']\n",
    "        #print \"graph_name =\"+ value['name'] +\" id=\" + str(gidx)\n",
    "#        graph_map[gidx] = sample_worker(graph,min_pattern_size,max_pattern_size, sample_size, can_map)\n",
    "        #print 'graph_'+str(gidx)+' is processed'\n",
    "    \n",
    "    print \"start counting patterns ...\"\n",
    "    input_graphs = [(gidx, value['graph'],min_pattern_size,max_pattern_size, sample_size, can_map) for gidx, value in graph_set.items()]  \n",
    "    \n",
    "    graph_map = []\n",
    "    for i,graph in enumerate(input_graphs):\n",
    "        graph_map.append(pattern_counter_in_graph(graph))\n",
    "        drawProgressBar(shell_out=True, \n",
    "                    begin=\"\", \n",
    "                        k=i+1, out_of=len(input_graphs), \n",
    "                        end=\"\")\n",
    "#     graph_map = Parallel(n_jobs=2, verbose=1, backend=\"multiprocessing\")(\n",
    "#        map(delayed(pattern_counter_in_graph), input_graphs))\n",
    "\n",
    "    ## which patterns occures how often\n",
    "    graph_map = { x:y for (x,y) in graph_map}   \n",
    "    \n",
    "    write(graph_map, output_file)\n",
    "    print \"\\ngraph_map is saved here : %s\"%output_file\n",
    "    return graph_map\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "###############################################################################\n",
    "##                               read graph set\n",
    "###############################################################################\n",
    "def read_graph_set(graph_set_file,threshold):\n",
    "    return read_gs(graph_set_file,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                      find the ids of all patterns with ps nodes\n",
    "## ps: pattern size\n",
    "###############################################################################\n",
    "def k_node_graphs(can_map, ps):\n",
    "    #output = {v['idx']  for k,v in can_map.items() if v['n']==ps }\n",
    "    output = {v['idx']  for k,v in can_map.items() if v['n']== ps and \n",
    "              nx.is_weakly_connected(get_subgraph(v['idx'], can_map))}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##         compute the sum over all count of k-node subgraphs\n",
    "## can_map = {graph_canonical_map:{'graph':..., 'idx':,..., 'n':....}}\n",
    "## k: k-node subgraphs, it shows the depth of the tree himap\n",
    "###############################################################################\n",
    "def z(all_knode_patterns, pat_cnt):\n",
    "    filter_pattern_count = {k:v for k,v in pat_cnt.items() if (k in all_knode_patterns)}\n",
    "    return float(0.1+sum([v for v in filter_pattern_count.values()]))\n",
    "    #return float(sum([v for v in filter_pattern_count.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                 n_c: number of paterns with exatly count e\n",
    "###############################################################################\n",
    "def n(e, pat_cnt):\n",
    "    l= pat_cnt.values()\n",
    "    return float(l.count(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                       compute discount value d\n",
    "## n_c:number of patterns with exactly count c\n",
    "###############################################################################\n",
    "def disc(c, pat_cnt):\n",
    "    n1 = n(1, pat_cnt)\n",
    "    n2 = n(2, pat_cnt)\n",
    "    n3 = n(3, pat_cnt)\n",
    "    n4 = n(4, pat_cnt)\n",
    "    y = float(n1) / n1+2*n2\n",
    "    if c==0:\n",
    "        return 0\n",
    "    elif c==1:\n",
    "        return y\n",
    "    elif c==2:\n",
    "        return 2-3*y*(float(n3)/n2)\n",
    "    else:\n",
    "        return 2-3*y*(float(n4)/n3)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##               compute probability based on the frequency\n",
    "###############################################################################\n",
    "def pf(pattern_idx,pattern_count, d, z_value):\n",
    "    if (pattern_idx in pattern_count.keys()):\n",
    "        count = pattern_count[pattern_idx]\n",
    "    else:\n",
    "        count = 0\n",
    "   # d = disc(count, pattern_count)\n",
    "    nominator = max(count-d,0)\n",
    "    \n",
    "    denominator = z_value\n",
    "    prob =  float(nominator)/float(denominator)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                 Normalization factor for base probability\n",
    "###############################################################################\n",
    "def norm_fact(all_knode_patterns, pattern_count, d):\n",
    "    filter_pattern_count = {k:v for k,v in pattern_count.items() if (k in all_knode_patterns)}\n",
    "    num_nn = len([v for v in filter_pattern_count.values() if v >= d])\n",
    "    b= sum([v for v in filter_pattern_count.values() if v < d])\n",
    "    return num_nn, b\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "###############################################################################\n",
    "##                               Mass value\n",
    "###############################################################################\n",
    "def mass(d, z_value, norm_fact, bounes):    \n",
    "    return (d/z_value)*norm_fact +(bounes/z_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                       compute base probability of a pattern\n",
    "## pb('')=pb(1)=1 because those occur in every possible graph\n",
    "###############################################################################\n",
    "def pb(wm, parent_kn,  pattern_id):\n",
    "    prob_base = 0\n",
    "    if pattern_id ==0 :\n",
    "        prob_base=1\n",
    "    else:\n",
    "        for parent_id, weight in wm[pattern_id].items():\n",
    "            prob_base = prob_base + pb(wm,parent_kn, parent_id)*weight\n",
    "            #prob_base += (parent_kn[parent_id]*weight)\n",
    "    return prob_base  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##           KN probability of the given pattern in the given graph\n",
    "## pattern count == pc[graph_id]\n",
    "## ps is pattern_size= number of nodes\n",
    "###############################################################################\n",
    "def pkn(can_map, pattern_count, w_map,parent_kn, pattern_idx, pattern_size, d, z_value, all_knode_patterns):\n",
    "   # all_knode_patterns = k_node_graphs(can_map, pattern_size)\n",
    "   # z_value = z(all_knode_patterns, pattern_count)\n",
    "    p1= pf(pattern_idx, pattern_count, d, z_value)\n",
    "    if (d==0):\n",
    "        pkn = p1 \n",
    "    else:\n",
    "        p2 = pb(w_map,parent_kn, pattern_idx)\n",
    "        mass_factor , bonus = norm_fact(all_knode_patterns, pattern_count, d)\n",
    "        mass_value = mass(d, z_value,mass_factor, bonus)\n",
    "        pkn = p1 + (mass_value*p2)\n",
    "        \n",
    "    parent_kn[pattern_idx] = pkn\n",
    "    return pkn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                          compute graph vector\n",
    "## pc : pattern count in each graph of graph_set\n",
    "###############################################################################\n",
    "def get_graph_vector(pc, can_map, wei_map,parent_kn, number_nodes, d):\n",
    "    graph_vectores = {}\n",
    "    all_knode_patterns = k_node_graphs(can_map, number_nodes)\n",
    "    #print all_knode_patterns\n",
    "    for graph_id, patt_cnt in pc.items():\n",
    "        tmp_vect = {}\n",
    "        #print pc[graph_id]\n",
    "        #print all_knode_patterns\n",
    "        z_value = z(all_knode_patterns, pc[graph_id])\n",
    "        #print \"graph_id=\"+str(graph_id) + \" z_value=\" + str(z_value)\n",
    "        for pid in k_node_graphs(can_map, number_nodes):\n",
    "            p_pkn = pkn(can_map, pc[graph_id], wei_map,parent_kn, pid, number_nodes, d,z_value,all_knode_patterns)\n",
    "            tmp_vect[pid]=p_pkn\n",
    "        graph_vectores[graph_id] = tmp_vect\n",
    "    return graph_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                      find a graph in the can_map\n",
    "###############################################################################\n",
    "def get_subgraph(gidx, can_map):\n",
    "    tmp = [t for t in can_map.values() if t['idx']==int(gidx)][0]\n",
    "    graph= tmp['graph']\n",
    "    n= tmp['n']\n",
    "    g = recover_graph(graph,n, gidx)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##                 data points for classification\n",
    "###############################################################################    \n",
    "def data_points(hs, m):\n",
    "    instances = []\n",
    "    count = 0\n",
    "    for i in range(1,len(hs)+1):\n",
    "        for j in range(i+1, len(hs)+1):\n",
    "            label = -1 #'B'\n",
    "            d = hs[i]-hs[j]\n",
    "            if (math.fabs(d)>0.5):\n",
    "                if d>0:\n",
    "                    label = +1#'A'\n",
    "                count = count + 1\n",
    "                inst =m[i-1,:].tolist()[0] + m[j-1,:].tolist()[0]+[label]\n",
    "                instances.append(inst) \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_count_of_connected_patterns_of_a_graph(pc_graph, can_map):\n",
    "    output = []\n",
    "    for idx in pc_graph.keys():\n",
    "        g = get_subgraph(idx,can_map)\n",
    "        if nx.is_weakly_connected(g):\n",
    "            #print \"idx: %d\"%idx\n",
    "            #print \"nodes : %s\"%g.nodes()\n",
    "            #print \"edges : %s\"%g.edges()\n",
    "            #print \"count : %d\"%pc_graph[idx]\n",
    "            #print \"------\"\n",
    "            output.append((idx,pc_graph[idx]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class count_matrix(object):\n",
    "    def __init__(self, name, pattern_ids, graph_ids,count_matrix):\n",
    "        self.pattern_ids = pattern_ids\n",
    "        self.graph_ids = graph_ids\n",
    "        self.count_matrix = count_matrix\n",
    "        self.name = name\n",
    "    \n",
    "    def display_patterns(self, can_map):\n",
    "        for idx in self.pattern_ids:\n",
    "            g = get_subgraph(idx,can_map)\n",
    "            print \"idx: %d\"%idx\n",
    "            print \"nodes : %s\"%g.nodes()\n",
    "            print \"edges : %s\"%g.edges()\n",
    "            print \"------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "##  \n",
    "###############################################################################\n",
    "def pattern_count(num_nodes,threshold):\n",
    "    min_pattern_size = num_nodes\n",
    "    max_pattern_size = num_nodes\n",
    "    sample_size = 1000 # numbrt of samples\n",
    "    \n",
    "    \n",
    "    \n",
    "    normalized = True\n",
    "    print \"min_pattern_size: %d\"%min_pattern_size\n",
    "    print \"max_pattern_size: %d\"%max_pattern_size\n",
    "    print \"sample_size: %d\"%sample_size\n",
    "    \n",
    "    \n",
    "    can_map_file = \"./canonical_map/can_map_maxk6.p\"\n",
    "    himap_file = \"./canonical_map/himap_maxk6.p\"\n",
    "\n",
    "    \n",
    "    subgraph_count_file = \"./count_graph_set\"+\"_min:\"+ str(min_pattern_size)+\"_max:\"+str(max_pattern_size)\n",
    "    \n",
    "    print \"loading can_map and hi_map: %s %s\"%(can_map_file, himap_file)\n",
    "    can_map, weight_map = get_maps(can_map_file, himap_file)    \n",
    "       \n",
    "    output = []\n",
    "    for gs_id,graph_set_file in enumerate([\"graph_set.g\"]):\n",
    "        print \"processing: %s \"%graph_set_file\n",
    "        \n",
    "        pc = count_subgraphs(graph_set_file,\n",
    "                             min_pattern_size, max_pattern_size,\n",
    "                             sample_size,\n",
    "                             can_map, \n",
    "                             subgraph_count_file,\n",
    "                             threshold)\n",
    "\n",
    "        print \"pattern counting is done.\"\n",
    "    \n",
    "        all_count_matrices = {}\n",
    "        print \"computing the count matrices ...\"\n",
    "        for num_nodes in range(min_pattern_size,max_pattern_size+1):\n",
    "            #print \"pattern_size: %d\"%num_nodes\n",
    "            connected_patterns_idx = list(k_node_graphs(can_map,num_nodes))\n",
    "            #print \"list of all possible connected patterns (columns): %s\"%connected_patterns_idx\n",
    "            num_graphs = len(pc.keys())\n",
    "            num_patterns = len(connected_patterns_idx)\n",
    "            cnt_matrix = np.zeros((num_graphs,num_patterns))\n",
    "            #print \"graph ids in rows of count_matrix: %s\" %pc.keys()\n",
    "            for key in pc.keys():\n",
    "                count  = get_count_of_connected_patterns_of_a_graph(pc[key], can_map)\n",
    "                row = key\n",
    "                for (pattern_id, value) in count:\n",
    "                    if pattern_id not in connected_patterns_idx:\n",
    "                        continue\n",
    "                    col = connected_patterns_idx.index(pattern_id)\n",
    "                    cnt_matrix[row, col] = value\n",
    "            cm = count_matrix(num_nodes, connected_patterns_idx,pc.keys(),  cnt_matrix)\n",
    "            all_count_matrices[num_nodes] = cm \n",
    "        print \"all connected patterns are counted\"\n",
    "        output.append((graph_set_file, pc, can_map, all_count_matrices))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_pattern_size: 3\n",
      "max_pattern_size: 3\n",
      "sample_size: 1000\n",
      "loading can_map and hi_map: ./canonical_map/can_map_maxk6.p ./canonical_map/himap_maxk6.p\n",
      "processing: graph_set.g \n",
      "loading the graph_set_file ...: graph_set.g\n",
      "# graphs in graph_set: 3\n",
      "start counting patterns ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mesgarmn/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: `comb` is deprecated!\n",
      "Importing `comb` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.comb` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3[=========================](100.00%)\n",
      "graph_map is saved here : ./count_orig_graph_set_min:3_max:3\n",
      "pattern counting is done.\n",
      "computing the count matrices ...\n",
      "all connected patterns are counted\n"
     ]
    }
   ],
   "source": [
    "### LCG count 3-node\n",
    "for tr in [0.0]:\n",
    "    output = pattern_count(num_nodes=3, threshold=tr)\n",
    "    with open('./pattern_count_3node.pkl','wb') as h:\n",
    "         cpickle.dump(output,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
